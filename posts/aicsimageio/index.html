<!DOCTYPE html><html domain="jacksonmaxfield.github.io" lang="en"><head><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><meta content="default-src 'self';object-src 'none';script-src 'self' 'sha256-Ky9qZOPnMhQV/s7Fdb9TYAOfU4KtWNqCZaFK8tSzXa0=';style-src 'unsafe-inline';img-src 'self' data:" http-equiv="Content-Security-Policy"><link href="/img/favicon/favicon-192x192.png?hash=2089033c93" rel="icon" type="image/png"><meta content="#f9c412" name="theme-color"><title>AICSImageIO</title><meta content="AICSImageIO" property="og:title"><meta content="AICSImageIO and the plan to make a comprehensive, scalable, image reading and writing library in pure Python." name="description"><meta content="AICSImageIO and the plan to make a comprehensive, scalable, image reading and writing library in pure Python." property="og:description"><meta content="summary_large_image" name="twitter:card"><meta content="@jmaxfieldbrown" name="twitter:site"><meta content="@jmaxfieldbrown" name="twitter:creator"><meta content="https://jacksonmaxfield.github.io/img/remote/2pGww4.png" property="og:image"><link href="https://jacksonmaxfield.github.io/posts/aicsimageio/" rel="canonical"><meta content="no-referrer-when-downgrade" name="referrer"><link href="/feed/feed.xml" rel="alternate" type="application/atom+xml" title="Jackson Maxfield Brown"><link href="/" rel="preconnect" crossorigin=""><script async="" defer="" src="/js/min.js?hash=54e8a28837"></script><script csp-hash="sha256-Ky9qZOPnMhQV/s7Fdb9TYAOfU4KtWNqCZaFK8tSzXa0=">if (/Mac OS X/.test(navigator.userAgent))document.documentElement.classList.add('apple')</script><style>:root{--primary: #54ffbd;--primary-dark: #005e5e;--main-width: calc(100vw - 3em)}main img{content-visibility:auto}header nav{z-index:1;position:fixed;top:0;left:0;width:100vw;padding:.375em 1.5em;background:rgba(255,255,255,.9);font-weight:200;text-align:right}@media (min-width:37.5em){:root{--main-width: calc(37.5em - 3em)}}dialog,share-widget{position:fixed;opacity:.9}share-widget{right:20px;bottom:20px}share-widget div{width:30px;height:30px;background-image:url(/img/share.svg);background-repeat:no-repeat;background-position:center}.apple share-widget div{background-image:url(/img/share-apple.svg)}body,share-widget button{margin:0}share-widget button:active{transform:scale(1.2)}dialog{background-color:#8dff80}header aside{font-style:italic}#nav,sub{position:relative}#nav{z-index:2}#reading-progress{z-index:1;background-color:var(--primary);width:100vw;position:absolute;left:0;top:0;bottom:0;transform:translate(-100vw,0);will-change:transform;pointer-events:none}#posts li{margin-bottom:.5em}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:100;src:url(/fonts/Inter-Thin.woff2) format("woff2"),url(/fonts/Inter-Thin.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:100;src:url(/fonts/Inter-ThinItalic.woff2) format("woff2"),url(/fonts/Inter-ThinItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:200;src:url(/fonts/Inter-ExtraLight.woff2) format("woff2"),url(/fonts/Inter-ExtraLight.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:200;src:url(/fonts/Inter-ExtraLightItalic.woff2) format("woff2"),url(/fonts/Inter-ExtraLightItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:300;src:url(/fonts/Inter-Light.woff2) format("woff2"),url(/fonts/Inter-Light.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:300;src:url(/fonts/Inter-LightItalic.woff2) format("woff2"),url(/fonts/Inter-LightItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:400;src:url(/fonts/Inter-Regular.woff2) format("woff2"),url(/fonts/Inter-Regular.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:400;src:url(/fonts/Inter-Italic.woff2) format("woff2"),url(/fonts/Inter-Italic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:500;src:url(/fonts/Inter-Medium.woff2) format("woff2"),url(/fonts/Inter-Medium.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:500;src:url(/fonts/Inter-MediumItalic.woff2) format("woff2"),url(/fonts/Inter-MediumItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:600;src:url(/fonts/Inter-SemiBold.woff2) format("woff2"),url(/fonts/Inter-SemiBold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:600;src:url(/fonts/Inter-SemiBoldItalic.woff2) format("woff2"),url(/fonts/Inter-SemiBoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:700;src:url(/fonts/Inter-Bold.woff2) format("woff2"),url(/fonts/Inter-Bold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:700;src:url(/fonts/Inter-BoldItalic.woff2) format("woff2"),url(/fonts/Inter-BoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:800;src:url(/fonts/Inter-ExtraBold.woff2) format("woff2"),url(/fonts/Inter-ExtraBold.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:800;src:url(/fonts/Inter-ExtraBoldItalic.woff2) format("woff2"),url(/fonts/Inter-ExtraBoldItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:normal;font-weight:900;src:url(/fonts/Inter-Black.woff2) format("woff2"),url(/fonts/Inter-Black.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI';font-style:italic;font-weight:900;src:url(/fonts/Inter-BlackItalic.woff2) format("woff2"),url(/fonts/Inter-BlackItalic.woff) format("woff")}@font-face{font-display:swap;font-family:'Inter UI var alt';font-weight:100 900;font-style:normal;font-named-instance:'Regular';src:url(/fonts/Inter-roman.var.woff2) format("woff2")}@font-face{font-display:swap;font-family:'Inter UI var alt';font-weight:100 900;font-style:italic;font-named-instance:'Italic';src:url(/fonts/Inter-italic.var.woff2) format("woff2")}button,html{line-height:1.15}html{-webkit-text-size-adjust:100%}h1{font-size:3em;line-height:1.25;margin:.67em 0 .5em;font-size:2.074rem;line-height:2.4rem;margin-bottom:1.36rem}a{background-color:transparent;color:#f9c412;text-decoration:none;color:var(--primary)}b,strong{font-weight:700}code{overflow-x:auto;border-radius:.3em;color:#ff4f5e;padding:0 .3em;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:90%;background:#e7e5e2}small{font-size:80%;color:#000}sub{font-size:75%;line-height:0;vertical-align:baseline;bottom:-.25em}img{border-style:none;max-width:100%;height:auto;margin:0 auto}button{font-family:inherit;font-size:100%;overflow:visible;text-transform:none}[type=button],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}h5{line-height:1.5em;font-size:1.25em;margin-bottom:1.2em;font-size:1rem;line-height:1.6rem;margin-bottom:1.36rem}body,p,ul{font-size:1em}p,ul{margin-bottom:1.5em}body,p,ul{font-size:1rem;line-height:1.6}p,ul{margin-bottom:1.36rem}@media (min-width:600px){h1{font-size:4.3978rem;line-height:4.4rem}body,h5,p,ul{font-size:1.1rem}h5{line-height:1.76rem}body,p,ul{line-height:1.6}h1,h5,p,ul{margin-bottom:1.496rem}}@media (min-width:1200px){h1{font-size:6.0756rem;line-height:6.72rem}body,h5,p,ul{font-size:1.2rem}h5{line-height:1.92rem}body,p,ul{line-height:1.6}h1,h5,p,ul{margin-bottom:1.632rem}}h1,h5,html{font-family:Inter UI,sans-serif}a:hover{text-decoration:underline}@media (max-width:767px){x:-moz-any-link{display:table-cell}}@supports (font-variation-settings:normal){html{font-family:Inter UI var alt,sans-serif}}button{border-radius:.3em;max-width:100%;background:#f2f2f2;color:#191919;cursor:pointer;display:inline-block;padding:.75em 1.5em;text-align:center;margin:0 .75em 1.5em 0}button:hover{background:#d9d9d9;color:#000}button:not([disabled]){background:#f9c412;color:#000;background:var(--primary)}button:not([disabled]):hover{background:#ba9005;color:#000;background:var(--primary-dark)}*{border:0;box-sizing:border-box}body,header nav a{font-family:Inter UI,sans-serif;color:#000}body{background:#fff}header{padding:4.5em 1.5em 3em;width:37.5em;margin:0 auto;text-align:center;max-width:100%;display:flex;align-items:center;flex-direction:column}header p,ul{margin-top:0}header nav h1{float:left;font-size:inherit;line-height:inherit;margin:0;text-align:left}header nav a{font-weight:700;text-decoration:none;margin-left:1.5em}header nav a:first-of-type{margin-left:auto}header nav a:last-of-type{margin-right:1.5em}main{max-width:70rem;margin:0 auto;border-top:.5px solid #000}article{max-width:100%;padding:1.5em;width:37.5em;margin:0 auto}li ul{margin-bottom:0}blockquote{border-left:1px solid #f9c412;padding:0 1.5em;margin:1.5em 0 1.5em 1.5em;border-left:1px solid var(--primary)}</style></head><body><header><nav><div id="nav"><h1><a href="/" title="Homepage">Jackson Maxfield Brown</a></h1><a href="/other_people/">Learning from Others</a> <a href="/research/">Research</a></div><div id="reading-progress" aria-hidden="true"></div></nav><h1>AICSImageIO</h1><aside>7 min read.</aside><dialog id="message"></dialog></header><main><article><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/aicsimageio/quilt-catalog-cells-1920w.webp 1920w, /img/aicsimageio/quilt-catalog-cells-1280w.webp 1280w, /img/aicsimageio/quilt-catalog-cells-640w.webp 640w, /img/aicsimageio/quilt-catalog-cells-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/aicsimageio/quilt-catalog-cells-1920w.jpg 1920w, /img/aicsimageio/quilt-catalog-cells-1280w.jpg 1280w, /img/aicsimageio/quilt-catalog-cells-640w.jpg 640w, /img/aicsimageio/quilt-catalog-cells-320w.jpg 320w" type="image/jpeg"><img alt="Single cell projections" decoding="async" height="991" loading="lazy" src="../../img/aicsimageio/quilt-catalog-cells.png" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1176px) min(calc(var(--main-width) * 0.842687074829932), 991px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1176 991'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAIAAAC6O5sJAAAACXBIWXMAAAsSAAALEgHS3X78AAAAq0lEQVQI1w3Bxw6CMAAA0P6LBxIPmhiFsDRgGGUUBLE4jibKLrQF9Ov1PaDI+jx9gjCmjOc4v13vjI0W9IG4kzmfXC8g/ZBll79hoEfbBUtBaOpaN5yybsPohHy/KkpTM4EoSiPjHgwIoRhfcZrRjvhHD0iS+mWTvXdI1Z/DNI2SrmwtHQJtc5j5FCNEW4oT/MhuvOPQ9MBqsW6K1jC09/MFLYjcoH426lb5Ab9oOQBV2AjeAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)" width="1176"></picture><br><sub>Single cell projections produced from <a href="https://github.com/allencellmodeling/actk">Automated Cell Toolkit</a>.</sub></p><p>This post will be about <a href="https://github.com/allencellmodeling/aicsimageio">AICSImageIO</a>, the work we have already completed, the things coming in the future, and other comments and tidbits along the way. In some ways, this is a rambling version of the <a href="https://github.com/allencellmodeling/aicsimageio/pull/150">"Mission and Roadmap" documents soon to be added to the AICSImageIO repository</a> so if you prefer to just read those documents, feel free.</p><h5 id="in-short">In Short <a href="#in-short" class="direct-link">#</a></h5><p>AICSImageIO aims to provide a <strong>consistent, intuitive, API for reading in or out-of-memory image pixel data and metadata, regardless of location,</strong> for the many existing proprietary microscopy file formats, and, an <strong>easy-to-use API for converting from proprietary file formats to an open, common, standard</strong> -- all using either language agnostic or pure Python tooling.</p><h5 id="background">Background <a href="#background" class="direct-link">#</a></h5><p>When I first started at Allen Cell, I was immediately tossed into reading and writing multi-dimensional volumetric image data -- something I had no prior experience in doing. Image manipulation in programming made <em>decent</em> sense to me in terms of n-dimensional array manipulation, but, I didn't have any idea of the current problems in scalable, robust, and unified image reading and writing.</p><p>Prior to Allen Cell, the largest images I had ever interacted with in-memory in programming were <em>small</em> -- a couple of MBs perhaps and all either 2D or 2D RGB (3D). What I would soon learn was that images can get <em>large</em>. Really large. On average, the microscopy images that Allen Cell works with are about 400 MBs in size and I think the most common array shape I interacted with was around (7, 75, 624, 924) -- 7 channel, 75 Z-stack images. These are large images when compared to what most people interact with on a daily basis but these weren't even close to the upper bound of the sizes of images we could possibly produce, and, most importantly, these images can fit into most workstation's memory. Notably, there was no time-series data in the above "most common" example, in the time-series case for Allen Cell, our files commonly were much larger, usually somewhere in the multi-GB range -- the largest I have seen was 200GB.</p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/aicsimageio/n-dim-render-1920w.webp 1920w, /img/aicsimageio/n-dim-render-1280w.webp 1280w, /img/aicsimageio/n-dim-render-640w.webp 640w, /img/aicsimageio/n-dim-render-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/aicsimageio/n-dim-render-1920w.jpg 1920w, /img/aicsimageio/n-dim-render-1280w.jpg 1280w, /img/aicsimageio/n-dim-render-640w.jpg 640w, /img/aicsimageio/n-dim-render-320w.jpg 320w" type="image/jpeg"><img alt="An image of a cell rendered in napari" decoding="async" height="550" loading="lazy" src="../../img/aicsimageio/n-dim-render.png" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 640px) min(calc(var(--main-width) * 0.859375), 550px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 640 550'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAYAAAA1WQxeAAAACXBIWXMAAAsSAAALEgHS3X78AAAAx0lEQVQI12NgZGT4z8DA8J9fguN/Zrzqf2N+FjAfCTP8Z2Zl+h/sJPV/oRD7/xQexv/FIbr/i2xU/kszARUwARXIyzD9txdn+Z9rJva/IEzl/5qe+P/nu+P+14qK/mfQUuX+X5Ng9L/QTub/5NyI/4fbYv/PX+n3f/p0v//8Auz/GfgVef/Huxv9r9CT+r8o2PD/XEup/9tStf9HWMgj3ADCVorS/7tTQv5XZZv9D9cUQXUkBDP+V1YX+19Y4vRfUkQILAbyIQCp2lag4E8CogAAAABJRU5ErkJggg=='%3E%3C/image%3E%3C/svg%3E&quot;)" width="640"></picture><br><sub>A three dimensional (ZYX) image of a cell rendered with <a href="https://napari.org">napari</a> with structure, membrane, and DNA channels visible.</sub></p><p>Images at Allen also come in a few formats, from proprietary file formats such as <code>CZI</code> and <code>LIF</code>, to open standards like <code>OME-TIFF</code> with each format containing their own metadata schema. This is incredibly important because while the underlying image pixel data is generally all the same structure -- "a bunch of YX planes in some shape or another", the metadata schemas can vary widely and contains important pieces of information such as the channel names, the pixel size, the acquisition setup, etc.</p><p>So what do you do when you have a scientist who wants to port some analysis code from using one image dataset to another, but, they have a couple of issues:</p><ul><li>the original dataset they used their analysis code against was written for reading and interacting with the metadata of a different file format</li><li>the original dataset contained files that were much smaller -- usually this is because they were using a small scale sample</li></ul><h5 id="too-many-formats">Too Many Formats <a href="#too-many-formats" class="direct-link">#</a></h5><p>Let's start by addressing how to create a "scalable" image reading library. Generally, when people talk about the "scalability" of something in programming they are referring to how well a program or infrastructure can handle more and more load, users, requests, etc. But, in the case of AICSImageIO, we use this term to mean:</p><blockquote><p>How easy is it to add support for reading a new proprietary file format?</p></blockquote><p>There are a couple of things to unpack here:</p><ul><li>How "easy" something is is a bad way to say "how well does the developer specification allow for 'my new cool custom image file format'."</li><li>Notice, we only mention "reading" a new file format, not writing. We are pretty set on this as we want to "encourage" that the easiest way to share data with others is with a single image writer to common standards.</li></ul><p>As previously mentioned, regardless of file format, <em>most</em> file formats store image pixel data relatively the same -- "a bunch of YX planes in some shape or another," and generally, when adding support for a new file format to the library we wanted to make that as easy as possible.</p><blockquote><p>If you provide this image Reader object with a method to read a buffer and return an n-dimensional array with the dimension short-names, we're good.</p></blockquote><p>This is similar to how other libraries have done it as well (i.e. <a href="https://github.com/imageio/imageio">imageio</a>). Where we differ however is in handling of metadata. It is hard to talk about which pieces of metadata are "the most useful" as everyone has different needs, but there are a few standouts: channels names, pixel size, dimension order and names, etc.</p><p>I <em>personally</em> think:</p><blockquote><p>the pieces of metadata that are most useful to computational scientists are those which enable the scientist to complete their work without ever having to <em>view</em> the file.</p></blockquote><p><sub>A disclaimer, I will always recommend viewing a sample of the images in a dataset regardless however to make sure that your programmatic understanding of the images you are operating on match your biological understanding.</sub></p><p>In this way, we, the developers of AICSImageIO should try to enable access to the pieces of metadata that are most common <em>across</em> file formats, <em>and</em>, allow for rapid development without having to constantly open and view different images.</p><p>So, in adding a file format to the library, <em>sure</em>, you can just add a Reader that will return the user "just the pixel data" but you should also find a way to read and parse the valuable bits of metadata.</p><h5 id="delayed-image-reading">Delayed Image Reading <a href="#delayed-image-reading" class="direct-link">#</a></h5><p>So great, we can scale and add readers to the library, and we can enforce that those image readers also read and parse the valuable bits of metadata. What happens when we scale to a multi-hundred GB image? How does the Reader interface change?</p><p>Fortunately for us, there are much smarter people out there that have already worked on "delayed / distributed array handling problems" for much longer than I have and in general, the problem of reading an image into memory is quite similar to creating a delayed array for that same image.</p><p>To expand our image reading specification, we simply added a requirement to image readers that requires that they must contain both a function to read the image into memory just like before, but also a function to read YX planes on request (or whatever chunk size they want).</p><p>There has been some difficulty getting these delayed arrays to operate exactly as intended, and largely this has admittedly been my over-promising of their value in all situations, but, this does work well as a solution for expanding the API to have both in-memory and out-of-memory data have the same functional interface.</p><h5 id="where-to-go">Where To Go <a href="#where-to-go" class="direct-link">#</a></h5><p>One of the problems of development on libraries like this that I have found is that once we made AICSImageIO 3.0 stable, we had to split our time between fixing user reported bugs, minor reworks to optimize behavior, and etc, versus simply continuing on with the high level goals. That isn't to take away from those activities as they are drastically important in shaping future work as well, it is simply that I have this excitement of adding <em>even more</em> value to the library, to show what all is possible with even more work but keep having to reign that excitement in (just a bit).</p><p>Again, in my opinion, the high level goal of AICSImageIO is to:</p><blockquote><p>provide a <strong>consistent, intuitive, API for reading in or out-of-memory image pixel data and metadata, regardless of location,</strong> for the many existing proprietary microscopy file formats, and, an <strong>easy-to-use API for converting from proprietary file formats to an open, common, standard</strong> -- all using either language agnostic or pure Python tooling.</p></blockquote><p>So we are actively working on adding support for <code>fsspec</code> (Filesystem Specification), a Python library that allows for path like handling of local or remote file systems.</p><p>We are cleaning up our API even further to have a standard for function and property naming and convention.</p><p>We are standardizing our Reader expansion further to allow for even more general, and safe, image reading with better scene management.</p><p>And the one that gets me most excited is our work on language agnostic metadata conversion. If we want to have a unified API for metadata access and interaction, well, it would be great that if instead of "emulating" the open standard if we just converted straight to the open standard. Many projects have already done parts of this work but are baked into the library itself, in a programming language, and we want to expand on their existing work by making their, and our work, converting between metadata schemas language agnostic so it can be imported and used in any language. (See the <a href="https://www.openmicroscopy.org/">OME</a> and <a href="https://github.com/ome/bioformats">bioformats</a> teams and projects)</p><p>Lastly, one of the other benefits of writing this library in pure Python is the ability to interact with the other existing Python ecosystem. We were one of the first teams to add an image reading plugin to <a href="https://napari.org">napari</a>, but, we hope to also make an image writing plugin after finishing our 4.0 series of changes, thus enabling a <strong>single</strong> library to manage the reading and writing of image data for both computational and non-computational users in pure Python.</p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/aicsimageio/napari-example-1920w.webp 1920w, /img/aicsimageio/napari-example-1280w.webp 1280w, /img/aicsimageio/napari-example-640w.webp 640w, /img/aicsimageio/napari-example-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="/img/aicsimageio/napari-example-1920w.jpg 1920w, /img/aicsimageio/napari-example-1280w.jpg 1280w, /img/aicsimageio/napari-example-640w.jpg 640w, /img/aicsimageio/napari-example-320w.jpg 320w" type="image/jpeg"><img alt="A full view of the napari viewer of the previous n-dimensional image render" decoding="async" height="684" loading="lazy" src="../../img/aicsimageio/napari-example.png" style="background-size:cover;contain-intrinsic-size: min(var(--main-width), 1084px) min(calc(var(--main-width) * 0.6309963099630996), 684px);background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1084 684'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAIAAAB1kpiRAAAACXBIWXMAAAsSAAALEgHS3X78AAAAvUlEQVQI12MwNrMzNXdUVdcVk5CVkFRQ1tVQUlfmE5IWEpeTl1Nh8AqKDE1MU1LTYmBgYORiybQQSZFgs1MXluNiZWBkYrB19nb2CpSWUwZKaytxpmmK1Adob5qRMMFVjw0oZGJt6+jqJy4hJyjGVhqi2+VjtKXQa/N0DwtzWaAsg5mJtV9YvIysIpAtJchRaGcwPcYoWksAyGVmZmYwMbd38w6WU1Dh4ebh4OGXUZANibAWFRNj4+Di4xMAAJ47H6TZHIWHAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&quot;)" width="1084"></picture><br><sub>A full view of the napari viewer rendering a three dimensional (ZYX) image of a cell rendered with <a href="https://napari.org">napari</a> with structure, membrane, and DNA channels visible made possible by directly reading an image with the <code>napari-aicsimageio</code> plugin.</sub></p><share-widget><button aria-label="Share" href="https://jacksonmaxfield.github.io/posts/aicsimageio/" on-click="share"><div></div></button></share-widget><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"AICSImageIO","image":["https://jacksonmaxfield.github.io../../img/aicsimageio/quilt-catalog-cells.png","https://jacksonmaxfield.github.io../../img/aicsimageio/n-dim-render.png","https://jacksonmaxfield.github.io../../img/aicsimageio/napari-example.png"],"author":"Jackson Maxfield Brown","genre":"Blog","publisher":{"@type":"Organization","name":"Jackson Maxfield Brown","logo":{"@type":"ImageObject","url":"/img/favicon/favicon-192x192.png?hash=2089033c93"}},"url":"https://jacksonmaxfield.github.io/posts/aicsimageio/","mainEntityOfPage":"https://jacksonmaxfield.github.io/posts/aicsimageio/","datePublished":"2020-09-28","dateModified":"2021-05-11","description":"Single cell projections produced from Automated Cell Toolkit. This post will be about AICSImageIO, the work we have already completed, the..."}</script><p>Published <time datetime="2020-09-28">28 Sep 2020</time></p></article></main></body></html>